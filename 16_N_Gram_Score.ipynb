{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11319f9d",
   "metadata": {},
   "source": [
    "An **n-gram score** is a metric that measures how well a language model (like the one that predicts text on your phone) predicts a sequence of words. It does this by checking how often a specific n-gram appears in a given body of text. Essentially, the score is a way to evaluate the \"predictive power\" of the model.\n",
    "\n",
    "Think of it like this: if a language model sees the phrase \"I went to the store and bought...\" it will look at all the words that follow \"bought\" in its training data. If \"milk\" is a very common word to follow \"bought,\" the model gives it a high probability, or a high \"n-gram score.\" The higher the score for a specific n-gram, the more likely it is to appear in a natural sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b641b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: [100, 102, 101, 103, 105, 104, 106, 105, 104, 106]\n",
      "\n",
      "3-gram Scores (Frequency):\n",
      "(100, 102, 101): 1\n",
      "(102, 101, 103): 1\n",
      "(101, 103, 105): 1\n",
      "(103, 105, 104): 1\n",
      "(105, 104, 106): 2\n",
      "(104, 106, 105): 1\n",
      "(106, 105, 104): 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample time series dataset (daily stock prices)\n",
    "data = {'Date': pd.to_datetime(['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04', '2025-01-05', '2025-01-06', '2025-01-07', '2025-01-08', '2025-01-09', '2025-01-10']),\n",
    "        'Price': [100, 102, 101, 103, 105, 104, 106, 105, 104, 106]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert prices to a list\n",
    "prices = df['Price'].tolist()\n",
    "\n",
    "def generate_ngrams(data, n):\n",
    "    \"\"\"\n",
    "    Generates n-grams from a list of data points.\n",
    "    \"\"\"\n",
    "    ngrams = []\n",
    "    # Loop from the first element up to the point where the window fits\n",
    "    for i in range(len(data) - n + 1):\n",
    "        # Slice the list to get a contiguous sequence of n items\n",
    "        ngrams.append(tuple(data[i:i + n]))\n",
    "    return ngrams\n",
    "\n",
    "def calculate_ngram_scores(data, n):\n",
    "    \"\"\"\n",
    "    Calculates the frequency (score) of each n-gram.\n",
    "    \"\"\"\n",
    "    # Generate the n-grams\n",
    "    ngrams = generate_ngrams(data, n)\n",
    "    # Count the frequency of each n-gram\n",
    "    ngram_scores = Counter(ngrams)\n",
    "    return ngram_scores\n",
    "\n",
    "# Let's generate and score 3-grams\n",
    "trigram_scores = calculate_ngram_scores(prices, 3)\n",
    "\n",
    "print(\"Original Data:\", prices)\n",
    "print(\"\\n3-gram Scores (Frequency):\")\n",
    "for trigram, score in trigram_scores.items():\n",
    "    print(f\"{trigram}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8af24f",
   "metadata": {},
   "source": [
    "# Assignment # 1\n",
    "\n",
    "Change the n value: Modify the calculate_ngram_scores function call to use n=2 (bigrams) and then n=4. What happens to the scores? Why do you think some scores might decrease as n gets larger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1863cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a58f3b",
   "metadata": {},
   "source": [
    "# Assignment # 2\n",
    "Probability vs. Frequency: The code above uses a simple frequency count. For a more sophisticated n-gram score, you could calculate the conditional probability. For example, for a trigram like (101, 103, 105), the score could be P(105 | 101, 103), which is the probability of 105 appearing after 101 and 103. How would you modify the Python code to calculate this type of score? Hint: You'll need to count the frequency of the full n-gram and the frequency of the (n-1)-gram that precedes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce6f040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab21d8b",
   "metadata": {},
   "source": [
    "# Assignment # 3\n",
    "Real-World Application: Imagine a dataset of daily average temperatures for your city over a few years. How could you use n-gram scores to find and predict seasonal patterns? For example, what would a high-scoring bigram (T1, T2) tell you about consecutive temperatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
